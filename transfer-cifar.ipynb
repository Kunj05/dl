{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16308a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455853c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 156ms/step - accuracy: 0.3899 - loss: 1.7169 - val_accuracy: 0.5561 - val_loss: 1.2600\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 160ms/step - accuracy: 0.5459 - loss: 1.2894 - val_accuracy: 0.5754 - val_loss: 1.1983\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 183ms/step - accuracy: 0.5847 - loss: 1.2048 - val_accuracy: 0.6012 - val_loss: 1.1530\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 181ms/step - accuracy: 0.5955 - loss: 1.1519 - val_accuracy: 0.6030 - val_loss: 1.1422\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 186ms/step - accuracy: 0.6120 - loss: 1.1107 - val_accuracy: 0.6076 - val_loss: 1.1265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1411081552505493, 0.600600004196167]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- Load CSVs ---\n",
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "test_df  = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# --- Split features/labels ---\n",
    "X_train = train_df.drop(['label'], axis=1).values.astype(\"float32\")\n",
    "y_train = train_df['label'].values\n",
    "X_test  = test_df.drop(['label'], axis=1).values.astype(\"float32\")\n",
    "y_test  = test_df['label'].values\n",
    "\n",
    "# --- Normalize ---\n",
    "X_train /= 255.0\n",
    "X_test  /= 255.0\n",
    "\n",
    "# --- Reshape to (H, W, C) ---\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_test  = X_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "# (Optional) upscale to 224x224 for VGG16 features:\n",
    "# X_train = tf.image.resize(X_train, (224, 224)).numpy()\n",
    "# X_test  = tf.image.resize(X_test,  (224, 224)).numpy()\n",
    "# input_shape = (224, 224, 3)\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# --- One-hot labels (10 classes) ---\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n",
    "\n",
    "# --- Base model ---\n",
    "base = VGG16(\n",
    "    weights=\"imagenet\",          # or your local .h5 path if you prefer\n",
    "    include_top=False,\n",
    "    input_shape=input_shape\n",
    ")\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# --- Head ---\n",
    "model = Sequential([\n",
    "    base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(10, activation='softmax')   # <-- 10 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# --- Train (now pass X and y) ---\n",
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.2,\n",
    "          epochs=5,\n",
    "          batch_size=64,\n",
    "          shuffle=True)\n",
    "\n",
    "# --- Evaluate ---\n",
    "model.evaluate(X_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0485b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 77ms/step - accuracy: 0.6006 - loss: 1.1333\n",
      "Validation Loss: 1.1411\n",
      "Validation Accuracy: 0.6006\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b3ceeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(31.5), np.float64(31.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_test was already resized to (n, 64, 64, 3) earlier.\n",
    "# Don't overwrite the existing 'img' variable (it is used in other cells).\n",
    "# Display the 60th test image directly.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[60])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7093918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Predicted class: 7\n",
      "True class: 7\n"
     ]
    }
   ],
   "source": [
    "# Predict using the 60th test image (not the one-hot label).\n",
    "# Add a batch dimension so the input shape is (1, 64, 64, 3).\n",
    "output = model.predict(np.expand_dims(X_test[60], axis=0))\n",
    "predicted_class = np.argmax(output, axis=1)[0]\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"True class:\", np.argmax(y_test[60]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32333ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining & Validation Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train','val'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec11278",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m1e-5\u001b[39m),\n\u001b[1;32m      9\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m history2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_data\u001b[49m,\n\u001b[1;32m     12\u001b[0m                      validation_data\u001b[38;5;241m=\u001b[39mval_data,\n\u001b[1;32m     13\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# e) Fine-tune (optional) — unfreeze few deeper conv layers\n",
    "# ------------------------------\n",
    "for layer in base.layers[-4:]:   #a unfreeze last 4 conv blocks\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history2 = model.fit(train_data,\n",
    "                     validation_data=val_data,\n",
    "                     epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
