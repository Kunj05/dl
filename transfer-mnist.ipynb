{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16308a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a71b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = VGG16(\n",
    "    weights=\"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "    include_top=False,\n",
    "    input_shape=(64,64,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16facec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Freeze base model ----\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "245e4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/k1fc46tx35x2tnh0g1fhdbb00000gn/T/ipykernel_34341/485481740.py:41: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base = tf.keras.applications.MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 47ms/step - accuracy: 0.8333 - loss: 0.5208 - val_accuracy: 0.9436 - val_loss: 0.1772\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 45ms/step - accuracy: 0.9332 - loss: 0.2079 - val_accuracy: 0.9488 - val_loss: 0.1541\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 45ms/step - accuracy: 0.9479 - loss: 0.1658 - val_accuracy: 0.9503 - val_loss: 0.1564\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 45ms/step - accuracy: 0.9563 - loss: 0.1394 - val_accuracy: 0.9603 - val_loss: 0.1262\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 43ms/step - accuracy: 0.9621 - loss: 0.1212 - val_accuracy: 0.9551 - val_loss: 0.1509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3002995e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load CSVs\n",
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "\n",
    "# Separate features and labels, convert to NumPy\n",
    "X_train = train.drop(columns=['label']).values\n",
    "y_train = train['label'].values\n",
    "\n",
    "X_test = test.drop(columns=['label']).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Normalize\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape for image format\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Convert to 3 channels (RGB)\n",
    "X_train = np.repeat(X_train, 3, axis=-1)\n",
    "X_test = np.repeat(X_test, 3, axis=-1)\n",
    "\n",
    "# Resize for pretrained model\n",
    "X_train = tf.image.resize(X_train, [64, 64]).numpy()\n",
    "X_test = tf.image.resize(X_test, [64, 64]).numpy()\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Define model (example with MobileNetV2 base)\n",
    "base = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(64, 64, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7439501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(102, activation='softmax')\n",
    "])\n",
    "\n",
    "# ---- Compile (train only new layers) ----\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Train ----\n",
    "model.fit(X_train, validation_split = 0.2, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f0485b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9486 - loss: 0.1631\n",
      "Validation Loss: 0.1485\n",
      "Validation Accuracy: 0.9549\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b3ceeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(63.5), np.float64(63.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_test was already resized to (n, 64, 64, 3) earlier.\n",
    "# Don't overwrite the existing 'img' variable (it is used in other cells).\n",
    "# Display the 60th test image directly.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[60])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7093918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Predicted class: 7\n",
      "True class: 7\n"
     ]
    }
   ],
   "source": [
    "# Predict using the 60th test image (not the one-hot label).\n",
    "# Add a batch dimension so the input shape is (1, 64, 64, 3).\n",
    "output = model.predict(np.expand_dims(X_test[60], axis=0))\n",
    "predicted_class = np.argmax(output, axis=1)[0]\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"True class:\", np.argmax(y_test[60]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32333ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train','val'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# e) Fine-tune (optional) — unfreeze few deeper conv layers\n",
    "# ------------------------------\n",
    "for layer in base.layers[-4:]:   #a unfreeze last 4 conv blocks\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history2 = model.fit(train_data,\n",
    "                     validation_data=val_data,\n",
    "                     epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
