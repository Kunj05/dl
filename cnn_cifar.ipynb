{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0ae71b",
   "metadata": {},
   "source": [
    "Implement the CNN model for classifying CIFAR10 image dataset by dividing the     \n",
    "model into following 4 stages: \n",
    "a. Loading and preprocessing the image data \n",
    "b. Defining the model's architecture \n",
    "c. Training the model \n",
    "d. Estimating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Loading and preprocessing the image data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "# load csv files\n",
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "test_df  = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "# separate labels + pixel data\n",
    "X_train = train_df.drop(['label'], axis=1).values\n",
    "y_train = train_df['label'].values\n",
    "\n",
    "X_test = test_df.drop(['label'], axis=1).values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# normalize pixel intensities\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test  = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# reshape → CIFAR10 shape: 32x32x3\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_test  = X_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "# one hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600a5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUBHAM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# b. Define the model's architecture\n",
    "\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "#     MaxPooling2D((2,2)),\n",
    "#     Conv2D(64, (3,3), activation='relu'),\n",
    "#     MaxPooling2D((2,2)),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model=models.Sequential()\n",
    "\n",
    "# Conv Block 1\n",
    "model.add(Conv2D(32,(3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Conv Block 2\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Conv Block 3\n",
    "model.add(Conv2D(128,(3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10170fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 34ms/step - accuracy: 0.4702 - loss: 1.5783 - val_accuracy: 0.6042 - val_loss: 1.1393\n",
      "Epoch 2/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 37ms/step - accuracy: 0.6449 - loss: 1.0157 - val_accuracy: 0.5930 - val_loss: 1.2117\n",
      "Epoch 3/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 41ms/step - accuracy: 0.6996 - loss: 0.8571 - val_accuracy: 0.6884 - val_loss: 0.9418\n",
      "Epoch 4/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 49ms/step - accuracy: 0.7331 - loss: 0.7685 - val_accuracy: 0.7416 - val_loss: 0.7468\n",
      "Epoch 5/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 37ms/step - accuracy: 0.7524 - loss: 0.7101 - val_accuracy: 0.7766 - val_loss: 0.6568\n",
      "Epoch 6/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 38ms/step - accuracy: 0.7801 - loss: 0.6363 - val_accuracy: 0.8064 - val_loss: 0.5604\n",
      "Epoch 7/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 45ms/step - accuracy: 0.7951 - loss: 0.5929 - val_accuracy: 0.7910 - val_loss: 0.5973\n",
      "Epoch 8/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 51ms/step - accuracy: 0.8084 - loss: 0.5502 - val_accuracy: 0.8254 - val_loss: 0.5160\n",
      "Epoch 9/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 43ms/step - accuracy: 0.8248 - loss: 0.5072 - val_accuracy: 0.8278 - val_loss: 0.5265\n",
      "Epoch 10/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 37ms/step - accuracy: 0.8355 - loss: 0.4755 - val_accuracy: 0.8184 - val_loss: 0.5424\n",
      "Epoch 11/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 41ms/step - accuracy: 0.8438 - loss: 0.4453 - val_accuracy: 0.8262 - val_loss: 0.5287\n",
      "Epoch 12/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 49ms/step - accuracy: 0.8535 - loss: 0.4246 - val_accuracy: 0.8422 - val_loss: 0.4899\n",
      "Epoch 13/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 50ms/step - accuracy: 0.8633 - loss: 0.3908 - val_accuracy: 0.8472 - val_loss: 0.4686\n",
      "Epoch 14/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 43ms/step - accuracy: 0.8682 - loss: 0.3748 - val_accuracy: 0.8394 - val_loss: 0.5048\n",
      "Epoch 15/15\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 38ms/step - accuracy: 0.8757 - loss: 0.3578 - val_accuracy: 0.8424 - val_loss: 0.4871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d546350f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c. Training the model\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676ff059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8339 - loss: 0.5099\n",
      "Test Loss: 0.5099309086799622\n",
      "Test Accuracy: 0.833899974822998\n"
     ]
    }
   ],
   "source": [
    "# d. Estimating the model's performance\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58dc7c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Trains the model for a fixed number of epochs (dataset iterations).\n",
      "\n",
      "Args:\n",
      "    x: Input data. It can be:\n",
      "        - A NumPy array (or array-like), or a list of arrays\n",
      "        (in case the model has multiple inputs).\n",
      "        - A backend-native tensor, or a list of tensors\n",
      "        (in case the model has multiple inputs).\n",
      "        - A dict mapping input names to the corresponding array/tensors,\n",
      "        if the model has named inputs.\n",
      "        - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n",
      "        `(inputs, targets, sample_weights)`.\n",
      "        - A `tf.data.Dataset` yielding `(inputs, targets)` or\n",
      "        `(inputs, targets, sample_weights)`.\n",
      "        - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n",
      "        or `(inputs, targets, sample_weights)`.\n",
      "        - A Python generator function yielding `(inputs, targets)` or\n",
      "        `(inputs, targets, sample_weights)`.\n",
      "    y: Target data. Like the input data `x`, it can be either NumPy\n",
      "        array(s) or backend-native tensor(s). If `x` is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or a Python generator function,\n",
      "        `y` should not be specified since targets will be obtained from\n",
      "        `x`.\n",
      "    batch_size: Integer or `None`.\n",
      "        Number of samples per gradient update.\n",
      "        If unspecified, `batch_size` will default to 32.\n",
      "        Do not specify the `batch_size` if your input data `x` is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or Python generator function\n",
      "        since they generate batches.\n",
      "    epochs: Integer. Number of epochs to train the model.\n",
      "        An epoch is an iteration over the entire `x` and `y`\n",
      "        data provided\n",
      "        (unless the `steps_per_epoch` flag is set to\n",
      "        something other than None).\n",
      "        Note that in conjunction with `initial_epoch`,\n",
      "        `epochs` is to be understood as \"final epoch\".\n",
      "        The model is not trained for a number of iterations\n",
      "        given by `epochs`, but merely until the epoch\n",
      "        of index `epochs` is reached.\n",
      "    verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "        \"auto\" becomes 1 for most cases.\n",
      "        Note that the progress bar is not\n",
      "        particularly useful when logged to a file,\n",
      "        so `verbose=2` is recommended when not running interactively\n",
      "        (e.g., in a production environment). Defaults to `\"auto\"`.\n",
      "    callbacks: List of `keras.callbacks.Callback` instances.\n",
      "        List of callbacks to apply during training.\n",
      "        See `keras.callbacks`. Note\n",
      "        `keras.callbacks.ProgbarLogger` and\n",
      "        `keras.callbacks.History` callbacks are created\n",
      "        automatically and need not be passed to `model.fit()`.\n",
      "        `keras.callbacks.ProgbarLogger` is created\n",
      "        or not based on the `verbose` argument in `model.fit()`.\n",
      "    validation_split: Float between 0 and 1.\n",
      "        Fraction of the training data to be used as validation data.\n",
      "        The model will set apart this fraction of the training data,\n",
      "        will not train on it, and will evaluate the loss and any model\n",
      "        metrics on this data at the end of each epoch. The validation\n",
      "        data is selected from the last samples in the `x` and `y` data\n",
      "        provided, before shuffling.\n",
      "        This argument is only supported when `x` and `y` are made of\n",
      "        NumPy arrays or tensors.\n",
      "        If both `validation_data` and `validation_split` are provided,\n",
      "        `validation_data` will override `validation_split`.\n",
      "    validation_data: Data on which to evaluate\n",
      "        the loss and any model metrics at the end of each epoch.\n",
      "        The model will not be trained on this data. Thus, note the fact\n",
      "        that the validation loss of data provided using\n",
      "        `validation_split` or `validation_data` is not affected by\n",
      "        regularization layers like noise and dropout.\n",
      "        `validation_data` will override `validation_split`.\n",
      "        It can be:\n",
      "        - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
      "        - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      "        arrays.\n",
      "        - A `keras.utils.PyDataset`, a `tf.data.Dataset`, a\n",
      "        `torch.utils.data.DataLoader` yielding `(inputs, targets)` or a\n",
      "        Python generator function yielding `(x_val, y_val)` or\n",
      "        `(inputs, targets, sample_weights)`.\n",
      "    shuffle: Boolean, whether to shuffle the training data before each\n",
      "        epoch. This argument is ignored when `x` is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or Python generator function.\n",
      "    class_weight: Optional dictionary mapping class indices (integers)\n",
      "        to a weight (float) value, used for weighting the loss function\n",
      "        (during training only).\n",
      "        This can be useful to tell the model to\n",
      "        \"pay more attention\" to samples from\n",
      "        an under-represented class. When `class_weight` is specified\n",
      "        and targets have a rank of 2 or greater, either `y` must be\n",
      "        one-hot encoded, or an explicit final dimension of `1` must\n",
      "        be included for sparse class labels.\n",
      "    sample_weight: Optional NumPy array or tensor of weights for\n",
      "        the training samples, used for weighting the loss function\n",
      "        (during training only). You can either pass a flat (1D)\n",
      "        NumPy array or tensor with the same length as the input samples\n",
      "        (1:1 mapping between weights and samples), or in the case of\n",
      "        temporal data, you can pass a 2D NumPy array or tensor with\n",
      "        shape `(samples, sequence_length)` to apply a different weight\n",
      "        to every timestep of every sample.\n",
      "        This argument is not supported when `x` is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or Python generator function.\n",
      "        Instead, provide `sample_weights` as the third element of `x`.\n",
      "        Note that sample weighting does not apply to metrics specified\n",
      "        via the `metrics` argument in `compile()`. To apply sample\n",
      "        weighting to your metrics, you can specify them via the\n",
      "        `weighted_metrics` in `compile()` instead.\n",
      "    initial_epoch: Integer.\n",
      "        Epoch at which to start training\n",
      "        (useful for resuming a previous training run).\n",
      "    steps_per_epoch: Integer or `None`.\n",
      "        Total number of steps (batches of samples) before declaring one\n",
      "        epoch finished and starting the next epoch. When training with\n",
      "        input tensors or NumPy arrays, the default `None` means that the\n",
      "        value used is the number of samples in your dataset divided by\n",
      "        the batch size, or 1 if that cannot be determined.\n",
      "        If `x` is a `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or Python generator function, the\n",
      "        epoch will run until the input dataset is exhausted. When\n",
      "        passing an infinitely repeating dataset, you must specify the\n",
      "        `steps_per_epoch` argument, otherwise the training will run\n",
      "        indefinitely.\n",
      "    validation_steps: Integer or `None`.\n",
      "        Only relevant if `validation_data` is provided.\n",
      "        Total number of steps (batches of samples) to draw before\n",
      "        stopping when performing validation at the end of every epoch.\n",
      "        If `validation_steps` is `None`, validation will run until the\n",
      "        `validation_data` dataset is exhausted. In the case of an\n",
      "        infinitely repeating dataset, it will run indefinitely. If\n",
      "        `validation_steps` is specified and only part of the dataset\n",
      "        is consumed, the evaluation will start from the beginning of the\n",
      "        dataset at each epoch. This ensures that the same validation\n",
      "        samples are used every time.\n",
      "    validation_batch_size: Integer or `None`.\n",
      "        Number of samples per validation batch.\n",
      "        If unspecified, will default to `batch_size`.\n",
      "        Do not specify the `validation_batch_size` if your data is a\n",
      "        `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      "        `torch.utils.data.DataLoader` or Python generator function\n",
      "        since they generate batches.\n",
      "    validation_freq: Only relevant if validation data is provided.\n",
      "        Specifies how many training epochs to run\n",
      "        before a new validation run is performed,\n",
      "        e.g. `validation_freq=2` runs validation every 2 epochs.\n",
      "\n",
      "Unpacking behavior for iterator-like inputs:\n",
      "    A common pattern is to pass an iterator like object such as a\n",
      "    `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
      "    which will in fact yield not only features (`x`)\n",
      "    but optionally targets (`y`) and sample weights (`sample_weight`).\n",
      "    Keras requires that the output of such iterator-likes be\n",
      "    unambiguous. The iterator should return a tuple\n",
      "    of length 1, 2, or 3, where the optional second and third elements\n",
      "    will be used for `y` and `sample_weight` respectively.\n",
      "    Any other type provided will be wrapped in\n",
      "    a length-one tuple, effectively treating everything as `x`. When\n",
      "    yielding dicts, they should still adhere to the top-level tuple\n",
      "    structure,\n",
      "    e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "    features, targets, and weights from the keys of a single dict.\n",
      "    A notable unsupported data type is the `namedtuple`. The reason is\n",
      "    that it behaves like both an ordered datatype (tuple) and a mapping\n",
      "    datatype (dict). So given a namedtuple of the form:\n",
      "    `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "    it is ambiguous whether to reverse the order of the elements when\n",
      "    interpreting the value. Even worse is a tuple of the form:\n",
      "    `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "    where it is unclear if the tuple was intended to be unpacked\n",
      "    into `x`, `y`, and `sample_weight` or passed through\n",
      "    as a single element to `x`.\n",
      "\n",
      "Returns:\n",
      "    A `History` object. Its `History.history` attribute is\n",
      "    a record of training loss values and metrics values\n",
      "    at successive epochs, as well as validation loss values\n",
      "    and validation metrics values (if applicable).\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\shubham\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\n",
      "\u001b[1;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83226adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
